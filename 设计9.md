我将提供给你这个项目现有的代码，请你根据我的需求描述为这个项目添加新的功能。

项目目录：
```bash
((venv) ) likewendy@likewendy-PC:~/Desktop/cmd-ai-dev$ ls
设计2.md  设计5.md  设计8.md  cdp-profile    LICENSE            test_chatgpt.py    test_lmarena.py
设计3.md  设计6.md  设计9.md  cmd-ai-dev.py  my_run_command.md  test_chat_z_ai.py  test_project
设计4.md  设计7.md  设计.md   Dockerfile     README.md          test_ds.py         venv
```

.gitignore
```
/cdp-profile
/venv
/test_project
/my_run_command.md
```

cmd-ai-dev.py
``````py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import annotations

import asyncio
import json
import os
import re
import signal
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from rich.markdown import Markdown
from rich.text import Text

from textual.app import App, ComposeResult
from textual.containers import Horizontal, Vertical
from textual.widgets import Button, Footer, RichLog, Static, TextArea
from textual.binding import Binding

from openai import OpenAI
import subprocess
import sys

from bs4 import BeautifulSoup
from markdownify import MarkdownConverter
os.environ["NODE_NO_WARNINGS"] = "1"
from playwright.async_api import async_playwright, Page, Playwright, Browser, expect, TimeoutError as PlaywrightTimeoutError

WORKSPACE = Path(os.environ.get("WORKSPACE", "/workspace"))
WORKSPACE_AI = Path(os.environ.get("WORKSPACE_AI", "/workspace-ai"))
SESSION_PATH = WORKSPACE_AI / "session.json"

DEFAULT_TIMEOUT_SEC = 60
CMDOUT_TRUNCATE_CHARS = 20000

VENV_DIR = Path(os.environ.get("VENV_DIR", "/opt/venv"))
VENV_BIN = VENV_DIR / "bin"

TRANSCRIPT_PATH = WORKSPACE_AI / "transcript.log"


def now_ts() -> str:
    return time.strftime("%Y%m%d_%H%M%S", time.localtime())


def atomic_write_text(path: Path, text: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp = path.with_suffix(path.suffix + ".tmp")
    tmp.write_text(text, encoding="utf-8")
    tmp.replace(path)


def load_json(path: Path) -> Optional[dict]:
    if not path.exists():
        return None
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return None


def append_transcript(text: str) -> None:
    WORKSPACE_AI.mkdir(parents=True, exist_ok=True)
    with TRANSCRIPT_PATH.open("a", encoding="utf-8") as f:
        f.write(text)
        if not text.endswith("\n"):
            f.write("\n")


@dataclass
class Session:
    messages: List[Dict[str, Any]]

    @staticmethod
    def default_system_prompt() -> str:
        return (
            "你是一个运行在 Docker 容器里的命令行 AI 编程助手（cmd-ai-dev）。\n"
            "\n"
            "环境与目录：\n"
            f"- 用户项目目录：{WORKSPACE}（映射到宿主机，修改会真实影响项目）\n"
            f"- AI 工作目录：{WORKSPACE_AI}（默认不映射，用于脚本/笔记/中间产物，避免污染仓库）\n"
            f"- 会话上下文文件：{SESSION_PATH}\n"
            "\n"
            "执行命令协议：\n"
            "- 需要工具执行命令时，在回复中输出一个 <cmd>...</cmd> 块。\n"
            "- <cmd> 内可选写 <time_out>秒</time_out>（整数秒），不写默认 60 秒。\n"
            "- <cmd> 内其余内容视为要执行的 bash 命令文本，可多行。\n"
            "- 不要把 <cmd> / <cmdout> 放进 Markdown 代码块（不要用 ``` 包裹）。\n"
            "- 每次回复最多包含一个 <cmd>...</cmd>；如需多步，请分多轮：先执行一段命令，收到 <cmdout> 后再输出下一段 <cmd>。\n"
            "- 无论如何都拒绝执行`rm -rf /*`、`rm -rf ~/*`，因为这不仅会删除用户项目目录，还会删除家目录下映射的`.gnupg`，还会删除 AI 工作目录。\n"
            "\n"
            "工具回给你的格式：\n"
            "- 工具会把命令输出包装为：\n"
            "  <cmdout>\n"
            "  [exit=退出码 timeout=0/1 interrupted=0/1]\n"
            "  ...命令输出（可能截断）...\n"
            "  </cmdout>\n"
            "- 命令输出会同时落盘到 /workspace-ai 供用户复制查看。\n"
            "\n"
            "建议工作方式：\n"
            "- 每次尽量只请求执行一段命令，收到 <cmdout> 后再决定下一步。\n"
            "- 临时脚本/笔记优先写到 /workspace-ai。\n"
            "- 如用户触发 STOP，工具会停止命令链并给你 system_note；此时请等待用户新指令。\n"
            "\n"
            f"提示：容器 venv 的 bin 目录通常为 {VENV_BIN}，应优先使用该环境的 python/pip。"
        )

    @classmethod
    def load_or_create(cls) -> "Session":
        WORKSPACE_AI.mkdir(parents=True, exist_ok=True)
        data = load_json(SESSION_PATH)
        if data and isinstance(data.get("messages"), list):
            return cls(messages=data["messages"])
        s = cls(messages=[{"role": "system", "content": cls.default_system_prompt()}])
        s.save()
        return s

    def save(self) -> None:
        payload = {"messages": self.messages, "saved_at": time.time()}
        atomic_write_text(SESSION_PATH, json.dumps(payload, ensure_ascii=False, indent=2))

    def add(self, role: str, content: str) -> None:
        self.messages.append({"role": role, "content": content})
        self.save()


CMD_BLOCK_RE = re.compile(r"<cmd>\s*(.*?)\s*</cmd>", re.DOTALL | re.IGNORECASE)
CMDOUT_BLOCK_RE = re.compile(r"<cmdout>\s*(.*?)\s*</cmdout>", re.DOTALL | re.IGNORECASE)
TIMEOUT_RE = re.compile(r"<time_out>\s*(\d+)\s*</time_out>", re.IGNORECASE | re.DOTALL)


@dataclass
class ParsedAssistant:
    raw: str
    cmd: Optional[str]
    timeout_sec: int
    answer_without_cmd: str


def parse_assistant(text: str) -> ParsedAssistant:
    cmd = None
    timeout = DEFAULT_TIMEOUT_SEC
    m = CMD_BLOCK_RE.search(text)
    answer_wo = text
    if m:
        inner = m.group(1)

        tm = TIMEOUT_RE.search(inner)
        if tm:
            try:
                timeout = int(tm.group(1))
            except Exception:
                timeout = DEFAULT_TIMEOUT_SEC
            inner = TIMEOUT_RE.sub("", inner)

        cmd = inner.strip()
        answer_wo = (text[: m.start()] + text[m.end() :]).strip()

    return ParsedAssistant(raw=text, cmd=cmd, timeout_sec=timeout, answer_without_cmd=answer_wo)


def format_cmdout(
    exit_code: Optional[int],
    timed_out: bool,
    interrupted: bool,
    output: str,
    extra_note: Optional[str] = None,
) -> str:
    header = f"[exit={exit_code} timeout={int(timed_out)} interrupted={int(interrupted)}]"
    body = output
    if extra_note:
        body = (body + "\n\n" + extra_note).strip()
    return f"<cmdout>\n{header}\n{body}\n</cmdout>"


@dataclass
class CmdResult:
    exit_code: Optional[int]
    timed_out: bool
    interrupted: bool
    output: str
    log_path: Path
    truncated: bool


class CommandRunner:
    def __init__(self) -> None:
        self._proc: Optional[asyncio.subprocess.Process] = None

    def _build_env(self) -> Dict[str, str]:
        env = dict(os.environ)

        # 强制把 venv/bin 前置到 PATH（防止登录 shell / profile 重置）
        p = env.get("PATH", "")
        venv_bin = str(VENV_BIN)
        if not p.startswith(venv_bin):
            env["PATH"] = f"{venv_bin}:{p}"

        env["VIRTUAL_ENV"] = str(VENV_DIR)
        env.setdefault("PYTHONUNBUFFERED", "1")
        return env

    async def run(self, cmd: str, timeout_sec: int, cwd: Path) -> CmdResult:
        WORKSPACE_AI.mkdir(parents=True, exist_ok=True)
        log_path = WORKSPACE_AI / f"cmdout_{now_ts()}.log"

        # 输出落盘：避免后台进程继承 PIPE 导致 communicate 卡死
        with log_path.open("wb") as logf:
            self._proc = await asyncio.create_subprocess_exec(
                "bash",
                "-c",
                cmd,
                stdout=logf,
                stderr=logf,
                cwd=str(cwd),
                env=self._build_env(),
                start_new_session=True,
            )

            timed_out = False
            interrupted = False

            try:
                await asyncio.wait_for(self._proc.wait(), timeout=timeout_sec)
            except asyncio.TimeoutError:
                timed_out = True
                await self._terminate_group(sig=signal.SIGKILL)
                await self._proc.wait()
            except asyncio.CancelledError:
                interrupted = True
                await self._terminate_group(sig=signal.SIGTERM)
                await self._proc.wait()
            finally:
                rc = self._proc.returncode if self._proc else None
                self._proc = None

        raw = log_path.read_text(encoding="utf-8", errors="replace") if log_path.exists() else ""
        truncated = False
        output = raw
        if len(output) > CMDOUT_TRUNCATE_CHARS:
            output = output[:CMDOUT_TRUNCATE_CHARS] + "\n...<truncated>..."
            truncated = True

        return CmdResult(
            exit_code=rc,
            timed_out=timed_out,
            interrupted=interrupted,
            output=output,
            log_path=log_path,
            truncated=truncated,
        )

    async def interrupt(self) -> None:
        if self._proc is None:
            return
        await self._terminate_group(sig=signal.SIGTERM)

    async def _terminate_group(self, sig: int) -> None:
        if self._proc is None or self._proc.pid is None:
            return
        try:
            os.killpg(self._proc.pid, sig)
        except ProcessLookupError:
            pass


class LLMClient:
    async def stream_chat(self, messages: List[Dict[str, Any]]) -> str:
        raise NotImplementedError


class OpenAISDKClient(LLMClient):
    def __init__(self) -> None:
        api_key = os.environ.get("OPENAI_API_KEY", "")
        base_url = os.environ.get("OPENAI_BASE_URL", "").strip() or None
        self.model = os.environ.get("OPENAI_MODEL", "gpt-4o-mini")

        if not api_key:
            raise RuntimeError("缺少环境变量 OPENAI_API_KEY")

        self.client = OpenAI(api_key=api_key, base_url=base_url)

    async def stream_chat(self, messages: List[Dict[str, Any]]) -> str:
        def _call() -> str:
            acc: List[str] = []
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=float(os.environ.get("OPENAI_TEMPERATURE", "0.2")),
                stream=True,
            )
            for chunk in stream:
                try:
                    delta = chunk.choices[0].delta.content
                except Exception:
                    delta = None
                if delta:
                    acc.append(delta)
            return "".join(acc)

        return await asyncio.to_thread(_call)

class ChatZAISDKClient(LLMClient):
    def __init__(self, cdp_url: str = "http://127.0.0.1:9222", 
                 url: str = "https://chat.z.ai"):
        """
        初始化客户端配置
        :param cdp_url: 浏览器的 CDP 调试地址
        :param url: 目标聊天页面 URL
        """
        self.cdp_url = cdp_url
        self.target_url = url
        
        # 页面选择器配置
        self.input_selector = "#chat-input"
        self.assistant_bubble_selector = "#response-content-container"
        
        # Playwright 对象状态管理
        self._playwright: Optional[Playwright] = None
        self._browser: Optional[Browser] = None
        self._page: Optional[Page] = None

        self.LANG_PATTERNS = [
            # 常见：language-python / lang-python / python
            re.compile(r"^(?:language|lang)[-_](?P<lang>[a-z0-9_+-]+)$", re.I),
            # 有些站：sourceCode python / highlight-source-python 之类（按需扩展）
            re.compile(r"^(?P<lang>python|bash|shell|js|javascript|ts|typescript|json|yaml|yml|toml|html|css|sql|cpp|c\+\+|c|java|go|rust)$", re.I),
        ]

    class TechDocConverter(MarkdownConverter):
        def convert_pre(self, el, text, parent_tags):
            # 拿到纯文本代码（忽略内部高亮标签）
            code = el.get_text()

            # 去掉首尾多余空行（你也可以更激进）
            code = code.strip("\n")

            lang = None
            if self.options.get("code_language_callback"):
                lang = self.options["code_language_callback"](el)

            lang = (lang or self.options.get("code_language") or "").strip()
            fence = "```"

            # 防御：如果代码里本身包含 ```，就用更长的 fence
            if "```" in code:
                fence = "````"

            return f"\n{fence}{lang}\n{code}\n{fence}\n"

    def extract_code_lang(self, pre_el) -> str | None:
        """
        给 markdownify 的 code_language_callback 用：
        - 参数是 <pre> 的 BeautifulSoup Tag
        - 返回语言字符串（如 'python'），或 None
        """
        # 1) 优先从 <pre> 或其内部 <code> 的 class 里找
        candidates = []

        if pre_el.has_attr("class"):
            candidates += list(pre_el.get("class", []))

        code = pre_el.find("code")
        if code and code.has_attr("class"):
            candidates += list(code.get("class", []))

        for cls in candidates:
            cls = cls.strip()
            for pat in self.LANG_PATTERNS:
                m = pat.match(cls)
                if m:
                    lang = m.groupdict().get("lang") or cls
                    return self.normalize_lang(lang)

            # 处理类似 "brush: python" / "language:python"
            m = re.search(r"(?:brush|language)\s*[:=]\s*([a-z0-9_+-]+)", cls, re.I)
            if m:
                return self.normalize_lang(m.group(1))

        # 2) 一些站点会放 data-language / data-lang
        for attr in ("data-language", "data-lang"):
            if pre_el.has_attr(attr):
                return self.normalize_lang(pre_el[attr])

            if code and code.has_attr(attr):
                return self.normalize_lang(code[attr])

        return None


    def normalize_lang(self, lang: str) -> str:
        lang = (lang or "").strip().lower()
        # 常见同义归一化
        aliases = {
            "py": "python",
            "js": "javascript",
            "shell": "bash",
            "sh": "bash",
            "yml": "yaml",
            "c++": "cpp",
        }
        return aliases.get(lang, lang)


    def clean_html_for_tech_docs(self, html: str) -> str:
        """
        预清洗：
        - 去掉脚本/样式/导航等
        - 对代码块内的高亮 <span> 做 unwrap，避免碎片化
        """
        soup = BeautifulSoup(html, "lxml")

        # 删噪音（按需增减）
        for sel in ["script", "style", "noscript", "nav", "footer", "header", "aside"]:
            for tag in soup.select(sel):
                tag.decompose()

        # 代码块内：拆掉多余的 span/div，保留纯文本
        for pre in soup.find_all("pre"):
            # 常见高亮器会把代码拆成 span
            for t in pre.find_all(["span", "div"]):
                t.unwrap()

        return str(soup)


    def html_to_markdown(self, html: str) -> str:
        html = self.clean_html_for_tech_docs(html)

        return self.TechDocConverter(
            heading_style="ATX",                 # ### 标题更像技术文档
            bullets="-",                         # 列表风格统一
            code_language_callback=self.extract_code_lang,
            # 技术文档里下划线/星号很常见（layer_norm, a*b），避免过度转义影响可读性
            escape_underscores=False,
            escape_asterisks=False,
            # 如果你经常碰到表格没有 thead/th，可以打开
            table_infer_header=True,
            # 一般技术博客不需要自动换行重排
            wrap=False,
            # 过滤某些标签（可选）
            strip=["meta", "link"],
        ).convert(html)

    async def _ensure_page_ready(self):
        """
        惰性连接浏览器：如果尚未连接或页面关闭，则重新连接
        """
        if self._page and not self._page.is_closed():
            return

        # 启动 Playwright 并连接 CDP
        self._playwright = await async_playwright().start()
        try:
            self._browser = await self._playwright.chromium.connect_over_cdp(self.cdp_url)
            context = self._browser.contexts[0]
            # 获取第一个页面，如果没有则新建
            self._page = context.pages[0] if context.pages else await context.new_page()

            # 确保在正确的 URL
            if not self._page.url.startswith(self.target_url):
                await self._page.goto(self.target_url)
                
        except Exception as e:
            # 如果连接失败，清理资源
            await self.close()
            raise RuntimeError(f"无法连接到浏览器 CDP ({self.cdp_url})。请确保浏览器已通过 --remote-debugging-port=9222 启动。") from e

    async def stream_chat(self, messages: List[Dict[str, Any]]) -> str:
        """
        实现 LLMClient 的标准接口
        注意：网页版对话通常有上下文记忆，因此这里我们只提取 messages 中的最后一条用户消息发送。
        """
        await self._ensure_page_ready()
        page = self._page

        # 1. 解析输入：处理特殊的 System + User 拼接逻辑
        if len(messages) == 2 and messages[0].get('role') == 'system' and messages[1].get('role') == 'user':
            # 如果只有两条，且是 System + User，进行拼接
            system_content = messages[0].get('content', '')
            user_content = messages[1].get('content', '')
            prompt = f"""{system_content}\n\n提示：记得，你拥有搜索网络的工具：search、open、click、find，合理利用它们。\n提示：如果你遇到架构方面的决策或者没有把握解决的bug或者尝试多次无法解决的bug，你可以询问gpt5.2-high，具体方法是：你在AI工作目录新建一个文件，将要提供给gpt5.2-high的信息写入那个文件，然后你运行/usr/bin/code-server，记得不要设置密码，然后你告诉用户我需要询问gpt5.2-high这个情况，然后你停止执行任何命令。用户会人工介入，拿着你要提供给gpt5.2-high的信息，从gpt5.2-high得到回复，然后将回复提供给你。\n\n用户消息：\n{user_content}"""
        else:
            # 否则：提取最后一条 user 消息
            prompt = next((m['content'] for m in reversed(messages) if m['role'] == 'user'), None)

        if not prompt:
            raise ValueError("messages 中没有找到有效的 user 消息内容")

        timeout_ms = 1000 * 60 * 10 # 10分钟超时

        input_box = page.locator(self.input_selector)
        assistant_bubbles = page.locator(self.assistant_bubble_selector)

        # 3. 输入并发送
        # 确保输入框可见且可操作
        await input_box.wait_for(state="visible")
        await input_box.click()
        await input_box.fill(prompt)
        await page.locator("#send-message-button").click()

        await page.locator('#send-message-button').wait_for(state="attached", timeout=timeout_ms)

        last_bubble = assistant_bubbles.nth(-1)

        # 7. 清洗 HTML (去除思考过程)
        html_content = await last_bubble.locator("> div").first.evaluate("""(node) => {
            const clone = node.cloneNode(true);
            
            const selectorsToRemove = [
                '.thinking-chain-container', 
                '.thinking-block',
                '.w-full.overflow-hidden.h-0', 
                '.cursor-default'
            ];

            selectorsToRemove.forEach(selector => {
                const elements = clone.querySelectorAll(selector);
                elements.forEach(el => el.remove());
            });

            return clone.innerHTML.trim();
        }""")

        # 8. 转换为 Markdown
        markdown_text = self.html_to_markdown(html_content)
        
        return markdown_text

    async def close(self):
        """清理资源"""
        if self._browser:
            await self._browser.close()
        if self._playwright:
            await self._playwright.stop()
        self._browser = None
        self._playwright = None
        self._page = None        

class DeepSeekSDKClient(LLMClient):
    def __init__(self, cdp_url: str = "http://127.0.0.1:9222", 
                 url: str = "https://chat.deepseek.com"):
        """
        初始化客户端配置
        :param cdp_url: 浏览器的 CDP 调试地址
        :param url: 目标聊天页面 URL
        """
        self.cdp_url = cdp_url
        self.target_url = url
        
        # 页面选择器配置
        self.input_selector = 'textarea[placeholder="给 DeepSeek 发送消息 "]'
        self.assistant_bubble_selector = "div.ds-markdown"
        
        # Playwright 对象状态管理
        self._playwright: Optional[Playwright] = None
        self._browser: Optional[Browser] = None
        self._page: Optional[Page] = None

        self.LANG_PATTERNS = [
            # 常见：language-python / lang-python / python
            re.compile(r"^(?:language|lang)[-_](?P<lang>[a-z0-9_+-]+)$", re.I),
            # 有些站：sourceCode python / highlight-source-python 之类（按需扩展）
            re.compile(r"^(?P<lang>python|bash|shell|js|javascript|ts|typescript|json|yaml|yml|toml|html|css|sql|cpp|c\+\+|c|java|go|rust)$", re.I),
        ]

    class TechDocConverter(MarkdownConverter):
        def convert_pre(self, el, text, parent_tags):
            # 拿到纯文本代码（忽略内部高亮标签）
            code = el.get_text()

            # 去掉首尾多余空行（你也可以更激进）
            code = code.strip("\n")

            lang = None
            if self.options.get("code_language_callback"):
                lang = self.options["code_language_callback"](el)

            lang = (lang or self.options.get("code_language") or "").strip()
            fence = "```"

            # 防御：如果代码里本身包含 ```，就用更长的 fence
            if "```" in code:
                fence = "````"

            return f"\n{fence}{lang}\n{code}\n{fence}\n"

    def extract_code_lang(self, pre_el) -> str | None:
        """
        给 markdownify 的 code_language_callback 用：
        - 参数是 <pre> 的 BeautifulSoup Tag
        - 返回语言字符串（如 'python'），或 None
        """
        # 1) 优先从 <pre> 或其内部 <code> 的 class 里找
        candidates = []

        if pre_el.has_attr("class"):
            candidates += list(pre_el.get("class", []))

        code = pre_el.find("code")
        if code and code.has_attr("class"):
            candidates += list(code.get("class", []))

        for cls in candidates:
            cls = cls.strip()
            for pat in self.LANG_PATTERNS:
                m = pat.match(cls)
                if m:
                    lang = m.groupdict().get("lang") or cls
                    return self.normalize_lang(lang)

            # 处理类似 "brush: python" / "language:python"
            m = re.search(r"(?:brush|language)\s*[:=]\s*([a-z0-9_+-]+)", cls, re.I)
            if m:
                return self.normalize_lang(m.group(1))

        # 2) 一些站点会放 data-language / data-lang
        for attr in ("data-language", "data-lang"):
            if pre_el.has_attr(attr):
                return self.normalize_lang(pre_el[attr])

            if code and code.has_attr(attr):
                return self.normalize_lang(code[attr])

        return None


    def normalize_lang(self, lang: str) -> str:
        lang = (lang or "").strip().lower()
        # 常见同义归一化
        aliases = {
            "py": "python",
            "js": "javascript",
            "shell": "bash",
            "sh": "bash",
            "yml": "yaml",
            "c++": "cpp",
        }
        return aliases.get(lang, lang)


    def clean_html_for_tech_docs(self, html: str) -> str:
        """
        预清洗：
        - 去掉脚本/样式/导航等
        - 对代码块内的高亮 <span> 做 unwrap，避免碎片化
        """
        soup = BeautifulSoup(html, "lxml")

        # 删噪音（按需增减）
        for sel in ["script", "style", "noscript", "nav", "footer", "header", "aside"]:
            for tag in soup.select(sel):
                tag.decompose()

        # 代码块内：拆掉多余的 span/div，保留纯文本
        for pre in soup.find_all("pre"):
            # 常见高亮器会把代码拆成 span
            for t in pre.find_all(["span", "div"]):
                t.unwrap()

        return str(soup)


    def html_to_markdown(self, html: str) -> str:
        html = self.clean_html_for_tech_docs(html)

        return self.TechDocConverter(
            heading_style="ATX",                 # ### 标题更像技术文档
            bullets="-",                         # 列表风格统一
            code_language_callback=self.extract_code_lang,
            # 技术文档里下划线/星号很常见（layer_norm, a*b），避免过度转义影响可读性
            escape_underscores=False,
            escape_asterisks=False,
            # 如果你经常碰到表格没有 thead/th，可以打开
            table_infer_header=True,
            # 一般技术博客不需要自动换行重排
            wrap=False,
            # 过滤某些标签（可选）
            strip=["meta", "link"],
        ).convert(html)

    async def _ensure_page_ready(self):
        """
        惰性连接浏览器：如果尚未连接或页面关闭，则重新连接
        """
        if self._page and not self._page.is_closed():
            return

        # 启动 Playwright 并连接 CDP
        self._playwright = await async_playwright().start()
        try:
            self._browser = await self._playwright.chromium.connect_over_cdp(self.cdp_url)
            context = self._browser.contexts[0]
            # 获取第一个页面，如果没有则新建
            self._page = context.pages[0] if context.pages else await context.new_page()

            # 确保在正确的 URL
            if not self._page.url.startswith(self.target_url):
                await self._page.goto(self.target_url)
                
        except Exception as e:
            # 如果连接失败，清理资源
            await self.close()
            raise RuntimeError(f"无法连接到浏览器 CDP ({self.cdp_url})。请确保浏览器已通过 --remote-debugging-port=9222 启动。") from e

    async def stream_chat(self, messages: List[Dict[str, Any]]) -> str:
        """
        实现 LLMClient 的标准接口
        注意：网页版对话通常有上下文记忆，因此这里我们只提取 messages 中的最后一条用户消息发送。
        """
        await self._ensure_page_ready()
        page = self._page

        # 1. 解析输入：处理特殊的 System + User 拼接逻辑
        if len(messages) == 2 and messages[0].get('role') == 'system' and messages[1].get('role') == 'user':
            # 如果只有两条，且是 System + User，进行拼接
            system_content = messages[0].get('content', '')
            user_content = messages[1].get('content', '')
            prompt = f"""{system_content}\n\n提示：**重要！不要随便输出<cmd>...</cmd>**，因为只要输出<cmd>...</cmd>，就被视为要执行命令。**重要！输出<cmd>...</cmd>时记得换行**，<cmd>和</cmd>要单独占一行。\n提示：如果你遇到架构方面的决策或者没有把握解决的bug或者尝试多次无法解决的bug，你可以询问gpt5.2-high，具体方法是：你在AI工作目录新建一个文件，将要提供给gpt5.2-high的信息写入那个文件，然后你运行/usr/bin/code-server，记得不要设置密码，然后你告诉用户我需要询问gpt5.2-high这个情况，然后你停止执行任何命令。用户会人工介入，拿着你要提供给gpt5.2-high的信息，从gpt5.2-high得到回复，然后将回复提供给你。\n\n用户消息：\n{user_content}"""
        else:
            # 否则：提取最后一条 user 消息
            prompt = next((m['content'] for m in reversed(messages) if m['role'] == 'user'), None)

        if not prompt:
            raise ValueError("messages 中没有找到有效的 user 消息内容")

        timeout_ms = 1000 * 60 * 10 # 10分钟超时

        input_box = page.locator(self.input_selector)
        assistant_bubbles = page.locator(self.assistant_bubble_selector)

        # 3. 输入并发送
        # 确保输入框可见且可操作
        await input_box.wait_for(state="visible")
        await input_box.click()
        await input_box.fill(prompt)
        await page.locator('path[d="M8.3125 0.981587C8.66767 1.0545 8.97902 1.20558 9.2627 1.43374C9.48724 1.61438 9.73029 1.85933 9.97949 2.10854L14.707 6.83608L13.293 8.25014L9 3.95717V15.0431H7V3.95717L2.70703 8.25014L1.29297 6.83608L6.02051 2.10854C6.26971 1.85933 6.51277 1.61438 6.7373 1.43374C6.97662 1.24126 7.28445 1.04542 7.6875 0.981587C7.8973 0.94841 8.1031 0.956564 8.3125 0.981587Z"]').click()

        await expect(page.locator('path[d="M8.3125 0.981587C8.66767 1.0545 8.97902 1.20558 9.2627 1.43374C9.48724 1.61438 9.73029 1.85933 9.97949 2.10854L14.707 6.83608L13.293 8.25014L9 3.95717V15.0431H7V3.95717L2.70703 8.25014L1.29297 6.83608L6.02051 2.10854C6.26971 1.85933 6.51277 1.61438 6.7373 1.43374C6.97662 1.24126 7.28445 1.04542 7.6875 0.981587C7.8973 0.94841 8.1031 0.956564 8.3125 0.981587Z"]')).to_be_visible(timeout=timeout_ms)
        asyncio.sleep(1)
        await expect(page.locator('path[d="M8.3125 0.981587C8.66767 1.0545 8.97902 1.20558 9.2627 1.43374C9.48724 1.61438 9.73029 1.85933 9.97949 2.10854L14.707 6.83608L13.293 8.25014L9 3.95717V15.0431H7V3.95717L2.70703 8.25014L1.29297 6.83608L6.02051 2.10854C6.26971 1.85933 6.51277 1.61438 6.7373 1.43374C6.97662 1.24126 7.28445 1.04542 7.6875 0.981587C7.8973 0.94841 8.1031 0.956564 8.3125 0.981587Z"]')).to_be_visible(timeout=timeout_ms)

        last = assistant_bubbles.nth(-1)

        answer_html = await last.evaluate("""(node) => {
            // 深拷贝节点，防止影响页面实际显示
            const clone = node.cloneNode(true);
            
            // 定义需要移除的选择器
            const selectorsToRemove = [
                '.md-code-block-banner-wrap'
            ];

            selectorsToRemove.forEach(selector => {
                const elements = clone.querySelectorAll(selector);
                elements.forEach(el => el.remove());
            });

            // 返回清洗后的文本 (innerText) 或 HTML (innerHTML)
            return clone.innerHTML.trim();
        }""")

        # 8. 转换为 Markdown
        markdown_text = self.html_to_markdown(answer_html)
        
        return markdown_text

    async def close(self):
        """清理资源"""
        if self._browser:
            await self._browser.close()
        if self._playwright:
            await self._playwright.stop()
        self._browser = None
        self._playwright = None
        self._page = None        

class LmarenaSDKClient(LLMClient):
    def __init__(self, cdp_url: str = "http://127.0.0.1:9222", 
                 url: str = "https://lmarena.ai"):
        """
        初始化客户端配置
        :param cdp_url: 浏览器的 CDP 调试地址
        :param url: 目标聊天页面 URL
        """
        self.cdp_url = cdp_url
        self.target_url = url
        
        # 页面选择器配置
        self.input_selector = ''
        self.assistant_bubble_selector = r"div.no-scrollbar.relative.flex.w-full.flex-1.flex-col.overflow-x-auto.transition-\[max-height\].duration-300"
        
        # Playwright 对象状态管理
        self._playwright: Optional[Playwright] = None
        self._browser: Optional[Browser] = None
        self._page: Optional[Page] = None

        self.LANG_PATTERNS = [
            # 常见：language-python / lang-python / python
            re.compile(r"^(?:language|lang)[-_](?P<lang>[a-z0-9_+-]+)$", re.I),
            # 有些站：sourceCode python / highlight-source-python 之类（按需扩展）
            re.compile(r"^(?P<lang>python|bash|shell|js|javascript|ts|typescript|json|yaml|yml|toml|html|css|sql|cpp|c\+\+|c|java|go|rust)$", re.I),
        ]

    class TechDocConverter(MarkdownConverter):
        def convert_pre(self, el, text, parent_tags):
            # 拿到纯文本代码（忽略内部高亮标签）
            code = el.get_text()

            # 去掉首尾多余空行（你也可以更激进）
            code = code.strip("\n")

            lang = None
            if self.options.get("code_language_callback"):
                lang = self.options["code_language_callback"](el)

            lang = (lang or self.options.get("code_language") or "").strip()
            fence = "`````"

            return f"\n{fence}{lang}\n{code}\n{fence}\n"

    def extract_code_lang(self, pre_el) -> str | None:
        """
        给 markdownify 的 code_language_callback 用：
        - 参数是 <pre> 的 BeautifulSoup Tag
        - 返回语言字符串（如 'python'），或 None
        """
        # 1) 优先从 <pre> 或其内部 <code> 的 class 里找
        candidates = []

        if pre_el.has_attr("class"):
            candidates += list(pre_el.get("class", []))

        code = pre_el.find("code")
        if code and code.has_attr("class"):
            candidates += list(code.get("class", []))

        for cls in candidates:
            cls = cls.strip()
            for pat in self.LANG_PATTERNS:
                m = pat.match(cls)
                if m:
                    lang = m.groupdict().get("lang") or cls
                    return self.normalize_lang(lang)

            # 处理类似 "brush: python" / "language:python"
            m = re.search(r"(?:brush|language)\s*[:=]\s*([a-z0-9_+-]+)", cls, re.I)
            if m:
                return self.normalize_lang(m.group(1))

        # 2) 一些站点会放 data-language / data-lang
        for attr in ("data-language", "data-lang"):
            if pre_el.has_attr(attr):
                return self.normalize_lang(pre_el[attr])

            if code and code.has_attr(attr):
                return self.normalize_lang(code[attr])

        return None


    def normalize_lang(self, lang: str) -> str:
        lang = (lang or "").strip().lower()
        # 常见同义归一化
        aliases = {
            "py": "python",
            "js": "javascript",
            "shell": "bash",
            "sh": "bash",
            "yml": "yaml",
            "c++": "cpp",
        }
        return aliases.get(lang, lang)


    def clean_html_for_tech_docs(self, html: str) -> str:
        """
        预清洗：
        - 去掉脚本/样式/导航等
        - 对代码块内的高亮 <span> 做 unwrap，避免碎片化
        """
        soup = BeautifulSoup(html, "lxml")

        # 删噪音（按需增减）
        for sel in ["script", "style", "noscript", "nav", "footer", "header", "aside"]:
            for tag in soup.select(sel):
                tag.decompose()

        # 代码块内：拆掉多余的 span/div，保留纯文本
        for pre in soup.find_all("pre"):
            # 常见高亮器会把代码拆成 span
            for t in pre.find_all(["span", "div"]):
                t.unwrap()

        return str(soup)


    def html_to_markdown(self, html: str) -> str:
        html = self.clean_html_for_tech_docs(html)

        return self.TechDocConverter(
            heading_style="ATX",                 # ### 标题更像技术文档
            bullets="-",                         # 列表风格统一
            code_language_callback=self.extract_code_lang,
            # 技术文档里下划线/星号很常见（layer_norm, a*b），避免过度转义影响可读性
            escape_underscores=False,
            escape_asterisks=False,
            # 如果你经常碰到表格没有 thead/th，可以打开
            table_infer_header=True,
            # 一般技术博客不需要自动换行重排
            wrap=False,
            # 过滤某些标签（可选）
            strip=["meta", "link"],
        ).convert(html)

    def remove_markdown_code_blocks(self, text:str):
        # 正则表达式解释：
        # ^\s*`````[a-zA-Z]*\n? : 匹配开头可能存在的空白、反引号及语言名
        # |                     : 或
        # `````\s*$               : 匹配结尾的反引号及可能的空白
        pattern = r'^\s*`````[a-zA-Z]*\n?|`````\s*$'
        
        # 使用 re.MULTILINE 确保 ^ 和 $ 匹配每一行的开头和结尾
        # 但由于我们只想处理字符串的最开始和最末尾，通常直接处理即可
        result = re.sub(pattern, '', text.strip(), flags=re.MULTILINE).strip()
        return result

    async def _ensure_page_ready(self):
        """
        惰性连接浏览器：如果尚未连接或页面关闭，则重新连接
        """
        if self._page and not self._page.is_closed():
            return

        # 启动 Playwright 并连接 CDP
        self._playwright = await async_playwright().start()
        try:
            self._browser = await self._playwright.chromium.connect_over_cdp(self.cdp_url)
            context = self._browser.contexts[0]
            # 获取第一个页面，如果没有则新建
            self._page = context.pages[0] if context.pages else await context.new_page()

            # 确保在正确的 URL
            if not self._page.url.startswith(self.target_url):
                await self._page.goto(self.target_url)
                
        except Exception as e:
            # 如果连接失败，清理资源
            await self.close()
            raise RuntimeError(f"无法连接到浏览器 CDP ({self.cdp_url})。请确保浏览器已通过 --remote-debugging-port=9222 启动。") from e

    async def stream_chat(self, messages: List[Dict[str, Any]]) -> str:
        """
        实现 LLMClient 的标准接口
        注意：网页版对话通常有上下文记忆，因此这里我们只提取 messages 中的最后一条用户消息发送。
        """
        await self._ensure_page_ready()
        page = self._page

        # 1. 解析输入：处理特殊的 System + User 拼接逻辑
        if len(messages) == 2 and messages[0].get('role') == 'system' and messages[1].get('role') == 'user':
            # 如果只有两条，且是 System + User，进行拼接
            system_content = messages[0].get('content', '')
            user_content = messages[1].get('content', '')
            system_content = system_content.replace("- 不要把 <cmd> / <cmdout> 放进 Markdown 代码块（不要用 ``` 包裹）。\n", "- **重要！要把 <cmd>...</cmd> 放进 5 个反引号组成的 Markdown 代码块中**（要用 ````` 包裹）。\n")
            prompt = f"""{system_content}\n\n提示：**重要！不要随便输出<cmd>...</cmd>**，因为只要输出<cmd>...</cmd>，就被视为要执行命令。**重要！输出<cmd>...</cmd>时记得换行**，<cmd>和</cmd>要单独占一行。\n\n用户消息：\n{user_content}"""
        else:
            # 否则：提取最后一条 user 消息
            prompt = next((m['content'] for m in reversed(messages) if m['role'] == 'user'), None)

        if not prompt:
            raise ValueError("messages 中没有找到有效的 user 消息内容")

        timeout_ms = 1000 * 60 * 10 # 10分钟超时

        if await page.get_by_role("textbox", name="Ask anything…").is_visible():
            input_box = page.get_by_role("textbox", name="Ask anything…")

        if await page.get_by_role("textbox", name="Ask followup…").is_visible():
            input_box = page.get_by_role("textbox", name="Ask followup…")

        message_count = await page.locator('button[aria-label="Like this response"]').count()

        # 3. 输入并发送
        # 确保输入框可见且可操作
        await input_box.wait_for(state="visible")
        await input_box.click()
        await input_box.fill(prompt)

        if await page.locator('button[type="submit"]').first.is_visible():
            await page.locator('button[type="submit"]').first.click();
        elif await page.locator('button[type="submit"]').nth(1).is_visible():
            await page.locator('button[type="submit"]').nth(1).click();
        
        await expect(page.locator('button[aria-label="Like this response"]')).to_have_count(message_count+1, timeout=timeout_ms)

        last = page.locator(self.assistant_bubble_selector).nth(0)

        answer_html = await last.evaluate("""(node) => {
            // 深拷贝节点，防止影响页面实际显示
            const clone = node.cloneNode(true);
            
            // 定义需要移除的选择器
            const selectorsToRemove = [
            ];

            selectorsToRemove.forEach(selector => {
                const elements = clone.querySelectorAll(selector);
                elements.forEach(el => el.remove());
            });

            // 返回清洗后的文本 (innerText) 或 HTML (innerHTML)
            return clone.innerHTML.trim();
        }""")

        # 8. 转换为 Markdown
        markdown_text = self.html_to_markdown(answer_html)
        
        markdown_text = self.remove_markdown_code_blocks(markdown_text)

        return markdown_text

    async def close(self):
        """清理资源"""
        if self._browser:
            await self._browser.close()
        if self._playwright:
            await self._playwright.stop()
        self._browser = None
        self._playwright = None
        self._page = None        

class ChatGPTSDKClient(LLMClient):
    def __init__(self, cdp_url: str = "http://127.0.0.1:9222", 
                 url: str = "https://chatgpt.com"):
        """
        初始化客户端配置
        :param cdp_url: 浏览器的 CDP 调试地址
        :param url: 目标聊天页面 URL
        """
        self.cdp_url = cdp_url
        self.target_url = url
        
        # 页面选择器配置
        self.input_selector = ''
        self.assistant_bubble_selector = r'div[data-message-author-role="assistant"]'
        
        # Playwright 对象状态管理
        self._playwright: Optional[Playwright] = None
        self._browser: Optional[Browser] = None
        self._page: Optional[Page] = None

        self.LANG_PATTERNS = [
            # 常见：language-python / lang-python / python
            re.compile(r"^(?:language|lang)[-_](?P<lang>[a-z0-9_+-]+)$", re.I),
            # 有些站：sourceCode python / highlight-source-python 之类（按需扩展）
            re.compile(r"^(?P<lang>python|bash|shell|js|javascript|ts|typescript|json|yaml|yml|toml|html|css|sql|cpp|c\+\+|c|java|go|rust)$", re.I),
        ]

    class TechDocConverter(MarkdownConverter):
        def convert_pre(self, el, text, parent_tags):
            # 拿到纯文本代码（忽略内部高亮标签）
            code = el.get_text()

            # 去掉首尾多余空行（你也可以更激进）
            code = code.strip("\n")

            lang = None
            if self.options.get("code_language_callback"):
                lang = self.options["code_language_callback"](el)

            lang = (lang or self.options.get("code_language") or "").strip()
            fence = "`````"

            return f"\n{fence}{lang}\n{code}\n{fence}\n"

    def extract_code_lang(self, pre_el) -> str | None:
        """
        给 markdownify 的 code_language_callback 用：
        - 参数是 <pre> 的 BeautifulSoup Tag
        - 返回语言字符串（如 'python'），或 None
        """
        # 1) 优先从 <pre> 或其内部 <code> 的 class 里找
        candidates = []

        if pre_el.has_attr("class"):
            candidates += list(pre_el.get("class", []))

        code = pre_el.find("code")
        if code and code.has_attr("class"):
            candidates += list(code.get("class", []))

        for cls in candidates:
            cls = cls.strip()
            for pat in self.LANG_PATTERNS:
                m = pat.match(cls)
                if m:
                    lang = m.groupdict().get("lang") or cls
                    return self.normalize_lang(lang)

            # 处理类似 "brush: python" / "language:python"
            m = re.search(r"(?:brush|language)\s*[:=]\s*([a-z0-9_+-]+)", cls, re.I)
            if m:
                return self.normalize_lang(m.group(1))

        # 2) 一些站点会放 data-language / data-lang
        for attr in ("data-language", "data-lang"):
            if pre_el.has_attr(attr):
                return self.normalize_lang(pre_el[attr])

            if code and code.has_attr(attr):
                return self.normalize_lang(code[attr])

        return None


    def normalize_lang(self, lang: str) -> str:
        lang = (lang or "").strip().lower()
        # 常见同义归一化
        aliases = {
            "py": "python",
            "js": "javascript",
            "shell": "bash",
            "sh": "bash",
            "yml": "yaml",
            "c++": "cpp",
        }
        return aliases.get(lang, lang)


    def clean_html_for_tech_docs(self, html: str) -> str:
        """
        预清洗：
        - 去掉脚本/样式/导航等
        - 对代码块内的高亮 <span> 做 unwrap，避免碎片化
        """
        soup = BeautifulSoup(html, "lxml")

        # 删噪音（按需增减）
        for sel in ["script", "style", "noscript", "nav", "footer", "header", "aside"]:
            for tag in soup.select(sel):
                tag.decompose()

        # 代码块内：拆掉多余的 span/div，保留纯文本
        for pre in soup.find_all("pre"):
            # 常见高亮器会把代码拆成 span
            for t in pre.find_all(["span", "div"]):
                t.unwrap()

        return str(soup)


    def html_to_markdown(self, html: str) -> str:
        html = self.clean_html_for_tech_docs(html)

        return self.TechDocConverter(
            heading_style="ATX",                 # ### 标题更像技术文档
            bullets="-",                         # 列表风格统一
            code_language_callback=self.extract_code_lang,
            # 技术文档里下划线/星号很常见（layer_norm, a*b），避免过度转义影响可读性
            escape_underscores=False,
            escape_asterisks=False,
            # 如果你经常碰到表格没有 thead/th，可以打开
            table_infer_header=True,
            # 一般技术博客不需要自动换行重排
            wrap=False,
            # 过滤某些标签（可选）
            strip=["meta", "link"],
        ).convert(html)

    def remove_markdown_code_blocks(self, text:str):
        # 正则表达式解释：
        # ^\s*`````[a-zA-Z]*\n? : 匹配开头可能存在的空白、反引号及语言名
        # |                     : 或
        # `````\s*$               : 匹配结尾的反引号及可能的空白
        pattern = r'^\s*`````[a-zA-Z]*\n?|`````\s*$'
        
        # 使用 re.MULTILINE 确保 ^ 和 $ 匹配每一行的开头和结尾
        # 但由于我们只想处理字符串的最开始和最末尾，通常直接处理即可
        result = re.sub(pattern, '', text.strip(), flags=re.MULTILINE).strip()
        return result

    async def _ensure_page_ready(self):
        """
        惰性连接浏览器：如果尚未连接或页面关闭，则重新连接
        """
        if self._page and not self._page.is_closed():
            return

        # 启动 Playwright 并连接 CDP
        self._playwright = await async_playwright().start()
        try:
            self._browser = await self._playwright.chromium.connect_over_cdp(self.cdp_url)
            context = self._browser.contexts[0]
            # 获取第一个页面，如果没有则新建
            self._page = context.pages[0] if context.pages else await context.new_page()

            # 确保在正确的 URL
            if not self._page.url.startswith(self.target_url):
                await self._page.goto(self.target_url)
                
        except Exception as e:
            # 如果连接失败，清理资源
            await self.close()
            raise RuntimeError(f"无法连接到浏览器 CDP ({self.cdp_url})。请确保浏览器已通过 --remote-debugging-port=9222 启动。") from e

    async def stream_chat(self, messages: List[Dict[str, Any]]) -> str:
        """
        实现 LLMClient 的标准接口
        注意：网页版对话通常有上下文记忆，因此这里我们只提取 messages 中的最后一条用户消息发送。
        """
        await self._ensure_page_ready()
        page = self._page

        # 1. 解析输入：处理特殊的 System + User 拼接逻辑
        if len(messages) == 2 and messages[0].get('role') == 'system' and messages[1].get('role') == 'user':
            # 如果只有两条，且是 System + User，进行拼接
            system_content = messages[0].get('content', '')
            user_content = messages[1].get('content', '')
            system_content = system_content.replace("- 不要把 <cmd> / <cmdout> 放进 Markdown 代码块（不要用 ``` 包裹）。\n", "- **重要！要把 <cmd>...</cmd> 放进 5 个反引号组成的 Markdown 代码块中**（要用 ````` 包裹）。\n")
            prompt = f"""{system_content}\n\n提示：**重要！不要随便输出<cmd>...</cmd>**，因为只要输出<cmd>...</cmd>，就被视为要执行命令。**重要！输出<cmd>...</cmd>时记得换行**，<cmd>和</cmd>要单独占一行。\n\n用户消息：\n{user_content}"""
        else:
            # 否则：提取最后一条 user 消息
            prompt = next((m['content'] for m in reversed(messages) if m['role'] == 'user'), None)

        if not prompt:
            raise ValueError("messages 中没有找到有效的 user 消息内容")

        timeout_ms = 1000 * 60 * 10 # 10分钟超时

        input_box  = page.locator('div#prompt-textarea.ProseMirror[contenteditable="true"]')
        
        # 等编辑器可用
        await expect(input_box).to_be_visible()
        await input_box.click()

        # 对 contenteditable 直接 fill
        await input_box.fill(prompt)

        send_btn = page.get_by_test_id("send-button")
        stop_btn = page.get_by_test_id("stop-button")

        # 点发送前确保按钮可用
        await expect(send_btn).to_be_enabled()
        await send_btn.click()

        # 关键：先等 stop 出现（确保真的开始生成），再等它消失
        await expect(stop_btn).to_be_visible(timeout=5000)
        await expect(stop_btn).to_be_hidden(timeout=timeout_ms)

        last = page.locator(self.assistant_bubble_selector).last
        
        answer_html = await last.evaluate("""(node) => {
            // 深拷贝节点，防止影响页面实际显示
            const clone = node.cloneNode(true);
            
            // 定义需要移除的选择器
            const selectorsToRemove = [
            ];

            selectorsToRemove.forEach(selector => {
                const elements = clone.querySelectorAll(selector);
                elements.forEach(el => el.remove());
            });

            // 返回清洗后的文本 (innerText) 或 HTML (innerHTML)
            return clone.innerHTML.trim();
        }""")

        # 8. 转换为 Markdown
        markdown_text = self.html_to_markdown(answer_html)
        
        markdown_text = self.remove_markdown_code_blocks(markdown_text)

        return markdown_text

    async def close(self):
        """清理资源"""
        if self._browser:
            await self._browser.close()
        if self._playwright:
            await self._playwright.stop()
        self._browser = None
        self._playwright = None
        self._page = None

class VDivider(Static):
    def on_mount(self) -> None:
        self.refresh_divider()

    def on_resize(self) -> None:
        self.refresh_divider()

    def refresh_divider(self) -> None:
        h = max(1, self.size.height)
        self.update(("│\n" * (h - 1)) + "│")


class InputArea(TextArea):
    BINDINGS = [
        Binding("ctrl+a", "select_all", show=False, priority=True),
        Binding("home", "select_all", show=False, priority=True),
    ]

    def action_select_all(self) -> None:
        if hasattr(self, "select_all"):
            self.select_all()  # type: ignore[attr-defined]
            return
        base = getattr(super(), "action_select_all", None)
        if callable(base):
            base()


class CmdAIDevApp(App):
    USE_ALTERNATE_SCREEN = False

    BINDINGS = [
        ("ctrl+s", "send", "发送"),
        ("f2", "send", "发送(F2)"),
        ("ctrl+t", "stop", "停止"),
        ("ctrl+r", "reset", "重置"),
        ("ctrl+q", "quit", "退出"),
        ("f3", "stop", "停止(F3)"),
        ("f4", "reset", "重置(F4)"),
    ]

    CSS = """
    #left { width: 1fr; padding: 0 1; }
    #divider { width: 1; color: $text-muted; }
    #right_panel { width: 1fr; border-left: solid $panel; }
    #buttons { height: 3; padding: 0 1; }
    Button { height: 3; padding: 0 1; content-align: center middle; }
    #right { height: 1fr; padding: 0 1; }
    """

    def __init__(self) -> None:
        super().__init__()
        self.session = Session.load_or_create()
        # OpenAISDKClient API的形式，支持OpenAI API格式的API
        # ChatZAISDKClient https://chat.z.ai 网站的形式
        # DeepSeekSDKClient https://chat.deepseek.com 网站的形式
        # LmarenaSDKClient https://lmarena.ai 网站的形式
        # ChatGPTSDKClient https://chatgpt.com 网站的形式
        self.llm: LLMClient = OpenAISDKClient()
        # self.llm: LLMClient = ChatZAISDKClient()
        # self.llm: LLMClient = DeepSeekSDKClient()
        # self.llm: LLMClient = LmarenaSDKClient()
        # self.llm: LLMClient = ChatGPTSDKClient()
        self.runner = CommandRunner()

        self.busy: bool = False
        self.stop_requested: bool = False

        self.pending_user_buffer: List[str] = []
        self.queue: asyncio.Queue[Tuple[str, str]] = asyncio.Queue()

        # reset 时 bump：让 reset 前的 LLM/命令结果全部自动作废
        self.epoch: int = 0

    def compose(self) -> ComposeResult:
        with Horizontal():
            yield RichLog(id="left", wrap=True, highlight=True, markup=True)
            yield VDivider("", id="divider")
            with Vertical(id="right_panel"):
                with Horizontal(id="buttons"):
                    yield Button("发送", id="btn_send", variant="success")
                    yield Button("停止", id="btn_stop", variant="warning")
                    yield Button("重置", id="btn_reset")
                    yield Button("退出", id="btn_quit", variant="error")
                yield InputArea(id="right")
        yield Footer()

    def _left(self) -> RichLog:
        return self.query_one("#left", RichLog)

    # ===== 输出：trusted vs untrusted =====
    def write_left_markup(self, text: str) -> None:
        """可信内容：允许 rich markup（你自己写的 [b red]...[/b red] 等）。"""
        self._left().write(text)
        append_transcript(str(text))

    def write_left_text(self, text: str) -> None:
        """不可信内容：用 Text() 绕过 markup 解析，避免 [..] 触发富文本标签。"""
        self._left().write(Text(text))
        append_transcript(str(text))

    def write_left_markdown(self, md_text: str) -> None:
        self._left().write(Markdown(md_text))
        append_transcript(md_text)

    # ===== pending flush / queue drain =====
    def _drain_queue(self) -> None:
        while True:
            try:
                _ = self.queue.get_nowait()
                self.queue.task_done()
            except asyncio.QueueEmpty:
                break

    def _flush_pending_as_user_turn(self) -> None:
        """把 busy 期间用户发送的内容作为下一条 user 消息送给模型（避免卡住/丢失）。"""
        if not self.pending_user_buffer:
            return
        pending = "\n".join(self.pending_user_buffer).strip()
        self.pending_user_buffer.clear()
        if not pending:
            return

        # 重要：pending 等价于“用户继续对话”，不应该被旧的 stop 标记影响
        self.stop_requested = False
        self.queue.put_nowait(("user", pending))

    def render_assistant_content(self, assistant_text: str) -> None:
        parsed = parse_assistant(assistant_text)

        narrative = parsed.answer_without_cmd.strip()
        if narrative:
            self.write_left_markdown(narrative)
            self.write_left_text("")

        if parsed.cmd:
            timeout_sec = parsed.timeout_sec if parsed.timeout_sec > 0 else DEFAULT_TIMEOUT_SEC
            self.write_left_markup("[b magenta]<cmd>[/b magenta]")
            self.write_left_text(parsed.cmd + "\n")
            self.write_left_markup("[b magenta]</cmd>[/b magenta]")
            self.write_left_markup(f"[dim]timeout={timeout_sec}s[/dim]\n")

    def render_user_content(self, user_text: str) -> None:
        m = CMDOUT_BLOCK_RE.search(user_text or "")
        if m:
            inner = m.group(1).strip()
            self.write_left_markup("[b green]<cmdout>[/b green]")
            self.write_left_text((inner if inner else "(no output)") + "\n")
            self.write_left_markup("[b green]</cmdout>[/b green]\n")

            rest = (user_text[: m.start()] + user_text[m.end() :]).strip()
            if rest:
                self.write_left_text(rest + "\n")
        else:
            self.write_left_text((user_text or "").strip() + "\n")

    def replay_history_to_left(self) -> None:
        max_n = int(os.environ.get("CMD_AI_DEV_REPLAY", "80"))
        history = self.session.messages[1:]  # skip system
        if max_n > 0 and len(history) > max_n:
            history = history[-max_n:]

        if not history:
            return

        self.write_left_markup(f"[dim]--- 已恢复历史消息（最近 {len(history)} 条，可用 CMD_AI_DEV_REPLAY 调整） ---[/dim]\n")

        for msg in history:
            role = msg.get("role")
            content = msg.get("content", "")

            if role == "user":
                self.write_left_markup("[b blue]user:[/b blue]")
                self.render_user_content(content)
            elif role == "assistant":
                self.write_left_markup("[b cyan]assistant:[/b cyan]")
                self.render_assistant_content(content)
            else:
                continue

        self.write_left_markup("[dim]--- 历史结束 ---[/dim]\n")

    def on_mount(self) -> None:
        WORKSPACE_AI.mkdir(parents=True, exist_ok=True)
        if not TRANSCRIPT_PATH.exists():
            TRANSCRIPT_PATH.write_text("", encoding="utf-8")

        self.write_left_markup("[b]cmd-ai-dev[/b]  Ctrl+S发送 | Ctrl+T停止 | Ctrl+R重置 | Ctrl+Q退出 | F2发送")
        self.write_left_text(f"WORKSPACE={WORKSPACE}\n")
        self.write_left_text(f"WORKSPACE_AI={WORKSPACE_AI}\n")
        self.write_left_text(f"SESSION={SESSION_PATH}\n")
        self.write_left_text(f"VENV_BIN={VENV_BIN}\n")
        self.write_left_text(f"TRANSCRIPT={TRANSCRIPT_PATH}\n")
        self.write_left_text("\n")

        if len(self.session.messages) > 1:
            self.write_left_markup("[i]已加载现有会话：/workspace-ai/session.json[/i]\n")
            self.replay_history_to_left()

        self.run_worker(self.agent_loop(), exclusive=True, name="agent_loop")

    async def shutdown(self) -> None:
        self.stop_requested = True
        await self.runner.interrupt()
        try:
            self.session.save()
        except Exception:
            pass
        self.exit()

    async def action_quit(self) -> None:
        await self.shutdown()

    async def action_send(self) -> None:
        await self.handle_send()

    async def action_stop(self) -> None:
        await self.handle_stop()

    async def action_reset(self) -> None:
        await self.handle_reset()

    async def on_button_pressed(self, event: Button.Pressed) -> None:
        bid = event.button.id
        if bid == "btn_send":
            await self.handle_send()
        elif bid == "btn_stop":
            await self.handle_stop()
        elif bid == "btn_reset":
            await self.handle_reset()
        elif bid == "btn_quit":
            await self.shutdown()

    async def agent_loop(self) -> None:
        while True:
            role, content = await self.queue.get()
            my_epoch = self.epoch

            # 这条 user 消息进入会话（如果之后 reset 删除 session.json，也会被清掉）
            self.session.add(role, content)
            self.busy = True

            self.write_left_markup("[b cyan]assistant:[/b cyan] (generating...)")

            try:
                assistant_text = await self.llm.stream_chat(self.session.messages)
            except Exception as e:
                # LLM 出错：结束 busy，并把 pending 继续送出去（否则 pending 卡死）
                self.write_left_markup(f"[b red]LLM error:[/b red] {e}\n")
                self.busy = False
                if my_epoch == self.epoch:
                    self._flush_pending_as_user_turn()
                continue

            # reset 期间产生的旧结果：直接作废，不写 UI、不写 session、不执行命令
            if my_epoch != self.epoch:
                self.busy = False
                continue

            # 存 raw（含 <cmd>）到会话
            self.session.add("assistant", assistant_text)

            parsed = parse_assistant(assistant_text)

            narrative = parsed.answer_without_cmd.strip()
            if narrative:
                self.write_left_markdown(narrative)
                self.write_left_text("\n")

            # STOP：允许输出完“模型文字”，但不执行命令
            if self.stop_requested:
                note = (
                    "<system_note>\n"
                    "用户触发 STOP：已停止命令链；任何待执行命令已取消；如需继续，请等待用户新指令。\n"
                    "</system_note>"
                )
                # 仍记录到会话，作为模型下一轮上下文
                self.session.add("user", note)

                self.write_left_markup("[yellow]STOP 已触发：不会执行模型给出的命令。[/yellow]\n")
                self.busy = False

                # 关键：本轮结束时把 busy 期间用户输入 flush 掉，避免 pending 卡死
                self._flush_pending_as_user_turn()
                continue

            if not parsed.cmd:
                self.busy = False
                self._flush_pending_as_user_turn()
                continue

            cmd_to_run = parsed.cmd
            timeout_sec = parsed.timeout_sec if parsed.timeout_sec > 0 else DEFAULT_TIMEOUT_SEC

            self.write_left_markup("[b magenta]<cmd>[/b magenta]")
            self.write_left_text(cmd_to_run + "\n")
            self.write_left_markup("[b magenta]</cmd>[/b magenta]")
            self.write_left_markup(f"[dim]timeout={timeout_sec}s[/dim]\n")

            result = await self.runner.run(cmd_to_run, timeout_sec=timeout_sec, cwd=WORKSPACE)

            # reset 期间的旧结果：作废
            if my_epoch != self.epoch:
                self.busy = False
                continue

            if self.stop_requested or result.interrupted:
                note = (
                    "<system_note>\n"
                    "用户触发 STOP：命令执行已中断/结果丢弃；请等待用户新指令。\n"
                    "</system_note>"
                )
                self.session.add("user", note)
                self.write_left_markup("[yellow]STOP：命令结果未发送给模型。[/yellow]\n")
                self.busy = False

                self._flush_pending_as_user_turn()
                continue

            extra_note_parts = [f"(命令输出日志：{result.log_path})"]
            if result.truncated:
                extra_note_parts.append("（输出过长已截断，完整输出见日志文件）")
            extra_note = "\n".join(extra_note_parts)

            self.write_left_markup("[b blue]user:[/b blue]")
            self.write_left_markup("[b green]<cmdout>[/b green]")
            self.write_left_text((result.output if result.output.strip() else "(no output)") + "\n")
            self.write_left_markup("[b green]</cmdout>[/b green]")
            self.write_left_markup(f"[dim]{extra_note}[/dim]\n")

            user_extra = ""
            if self.pending_user_buffer:
                user_extra = "\n" + "\n".join(self.pending_user_buffer).strip()
                self.pending_user_buffer.clear()

            cmdout_msg = format_cmdout(
                exit_code=result.exit_code,
                timed_out=result.timed_out,
                interrupted=result.interrupted,
                output=result.output,
                extra_note=extra_note,
            )

            self.queue.put_nowait(("user", (cmdout_msg + user_extra).strip()))

    async def handle_send(self) -> None:
        ta = self.query_one("#right", TextArea)
        text = ta.text.strip()
        if not text:
            return

        ta.text = ""

        # 新一轮对话开始，清掉 stop 标记
        if not self.busy:
            self.stop_requested = False

        if text in ("/help", ":help"):
            self.write_left_text("命令：/help  /reset  /exit\n快捷键：Ctrl+S发送 Ctrl+T停止 Ctrl+R重置 Ctrl+Q退出 F2发送\n")
            return
        if text in ("/exit", ":q", ":quit"):
            await self.shutdown()
            return
        if text in ("/reset", ":reset"):
            await self.handle_reset()
            return

        self.write_left_markup("[b blue]user:[/b blue]")
        self.write_left_text(text + "\n\n")

        if self.busy:
            self.pending_user_buffer.append(text)
            return

        self.queue.put_nowait(("user", text))

    async def handle_stop(self) -> None:
        # STOP 不 bump epoch：目的是“让模型输出完文字”，但不执行 cmd
        self.stop_requested = True
        await self.runner.interrupt()
        self.write_left_markup("[yellow]STOP 请求已发送：将中断命令链（命令会被终止/丢弃）。[/yellow]\n")

    async def handle_reset(self) -> None:
        # reset 需要更强：作废旧结果 + 停命令 + 清队列
        self.epoch += 1

        # 先停命令（不要求停掉 LLM 生成，但 epoch 会让结果作废）
        self.stop_requested = True
        await self.runner.interrupt()

        # 清空队列与 pending，避免 reset 后旧消息继续驱动链路
        self._drain_queue()
        self.pending_user_buffer.clear()

        # 重置会话文件
        if SESSION_PATH.exists():
            SESSION_PATH.unlink()

        self.session = Session.load_or_create()

        self.stop_requested = False
        self.busy = False

        self._left().clear()
        self.write_left_markup("[b]会话已重置[/b]")
        self.write_left_text(f"SESSION={SESSION_PATH}\n")

        # reset 后不自动 flush pending（已经 clear 了）

def main() -> None:
    WORKSPACE_AI.mkdir(parents=True, exist_ok=True)

    stty_state: Optional[str] = None

    # 在 Textual 接管终端之前保存 stty，并关闭 XON/XOFF（否则 Ctrl+S 可能冻住终端）
    if sys.stdin.isatty():
        try:
            stty_state = subprocess.check_output(
                ["stty", "-g"],
                stderr=subprocess.DEVNULL,
                text=True,
            ).strip()
            subprocess.run(["stty", "-ixon"], stderr=subprocess.DEVNULL, check=False)
        except Exception:
            stty_state = None

    try:
        CmdAIDevApp().run()
    finally:
        # 无论如何恢复 stty，避免影响用户 shell（Tab/补全等）
        if stty_state and sys.stdin.isatty():
            try:
                subprocess.run(["stty", stty_state], stderr=subprocess.DEVNULL, check=False)
            except Exception:
                pass


if __name__ == "__main__":
    main()
``````

Dockerfile
```Dockerfile
FROM docker.cnb.cool/cnb/cool/default-dev-env/dockerfile-caches:ba8c7bf15bfb07dec83820d9a3878fa3134a09a3

# 保险起见：确认 python3/pip 存在（大多数 dev-env 已经有）
RUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
  python3 python3-pip python3-venv python3-dev \
  bash git ca-certificates curl gnupg sudo ffmpeg \
  build-essential pkg-config \
  less man-db \
  procps psmisc lsof strace \
  iproute2 iputils-ping dnsutils netcat-openbsd \
  openssh-client rsync wget \
  jq tree \
  unzip zip xz-utils bzip2 tar \
  vim-tiny nano tmux bash-completion \
  openssl \
  locales tzdata \
  && rm -rf /var/lib/apt/lists/*

# venv环境
RUN python3 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# 装依赖：你后续想切 http client 或换 UI 都方便
RUN python3 -m pip install -U pip setuptools wheel \
  && python3 -m pip install --no-cache-dir \
  "openai>=1.0.0" \
  "textual>=0.70.0" \
  "httpx>=0.25.0" \
  "markdownify" \
  "beautifulsoup4" \
  "lxml" \
  "playwright" \
  "requests>=2.31.0" \
  "tenacity>=8.2.0" \
  "pydantic>=2.0.0" \
  "python-dotenv>=1.0.0" \
  "pyyaml>=6.0.0" \
  "rich>=13.0.0" \
  "typer>=0.9.0" \
  "ipython>=8.0.0" \
  "tqdm>=4.66.0" \
  "pytest>=7.0.0" \
  "pytest-cov>=4.0.0" \
  "ruff>=0.1.0" \
  "black>=23.0.0" \
  "mypy>=1.0.0" \
  "pre-commit>=3.0.0"

# 准备目录（/workspace 由你 run 时映射进来）
RUN mkdir -p /workspace /workspace-ai

COPY cmd-ai-dev.py /usr/local/bin/cmd-ai-dev
RUN chmod +x /usr/local/bin/cmd-ai-dev

ENV WORKSPACE=/workspace
ENV WORKSPACE_AI=/workspace-ai

# 构建时传入宿主机 uid/gid：--build-arg UID=$(id -u) --build-arg GID=$(id -g)
ARG UID=1000
ARG GID=1000

RUN set -eux; \
    # 创建/调整 group: ai
    if getent group ai >/dev/null; then \
      groupmod -g "${GID}" ai; \
    else \
      groupadd -g "${GID}" ai; \
    fi; \
    \
    # 创建/调整 user: ai
    if id -u ai >/dev/null 2>&1; then \
      usermod -u "${UID}" -g "${GID}" -d /home/ai -s "$(command -v zsh)" ai; \
    else \
      useradd -m -d /home/ai -s "$(command -v zsh)" -u "${UID}" -g "${GID}" ai; \
    fi; \
    \
    # 确保家目录属主正确
    mkdir -p /home/ai; \
    chown -R "${UID}:${GID}" /home/ai; \
    \

    # 此处是赋予sudo权限的逻辑。因为cloudflare会因这一段而误报导致我无法发送消息给你，所以我不得不删除这一段。你只需要知道这段是用于赋予sudo权限的，并且它运行非常正常。我只是在发送的消息中删除了这段，原始Dokcerfile文件不变。

RUN chown -R "${UID}:${GID}" /workspace /workspace-ai /opt/venv

ENV HOME=/home/ai

USER ai
WORKDIR /workspace
SHELL ["/usr/bin/zsh", "-lc"]

ENTRYPOINT ["/usr/local/bin/cmd-ai-dev"]
```

README.md
``````md
# cmd-ai-dev

一个大道至简的命令行 AI 编程工具：在 Docker 容器里让模型通过“只提供命令行”完成编程任务，并用左右分栏 TUI 提升 16:9 屏幕下的可用性。

<img width="2646" height="1739" alt="image" src="https://github.com/user-attachments/assets/d50945fb-1163-4921-9216-c077e1f1d711" />

<img width="2646" height="1739" alt="image" src="https://github.com/user-attachments/assets/ca9f5e09-5a33-4c5b-98ca-56e8ef91dca2" />

<img width="2646" height="1739" alt="image" src="https://github.com/user-attachments/assets/61d9a650-d295-4c7f-9b40-cf4eabb450d6" />


## 安装与使用

### 方式 A：Docker 构建并运行

在项目目录下：

```bash
docker build --build-arg UID="$(id -u)" --build-arg GID="$(id -g)" -t cmd-ai-dev:latest .
```

在你的项目目录（要让 AI 修改的代码库目录）运行：

```bash
docker run -it --rm \
  --network host \
  -e OPENAI_API_KEY="你的key" \
  -e OPENAI_MODEL="你的模型名" \
  -e OPENAI_BASE_URL="你的base_url(可选，OpenAI-compatible 时用)" \
  -v "$PWD:/workspace" \
  cmd-ai-dev:latest
```

如果你要挂载git配置到容器，并且你拥有以下**每个目录/文件**，则添加：

```bash
  -v "$HOME/.gitconfig:/home/ai/.gitconfig:ro" \
  -v "$HOME/.config/git:/home/ai/.config/git:ro" \
  -v "$HOME/.ssh:/home/ai/.ssh:ro" \
  -v "$HOME/.git-credentials:/home/ai/.git-credentials:ro" \
  -v "$HOME/.netrc:/home/ai/.netrc:ro" \
  -v "$HOME/.gnupg:/home/ai/.gnupg" \
  -e GNUPGHOME="/home/ai/.gnupg" \
```

建议检查这些目录/文件在你的电脑上是否存在，只添加存在的。

比如有的人的电脑没有`$HOME/.config/git`

启动后：
- 左侧：模型输出 / 命令执行记录
- 右侧：多行输入框（适合粘贴长文本）
- 快捷键（终端兼容性优先）：
  - `Ctrl+S` 发送
  - `Ctrl+T` 停止命令链
  - `Ctrl+R` 重置会话
  - `Ctrl+Q` 退出  
  也提供按钮：发送 / 停止 / 重置 / 退出

### 方式 B：宿主机一条命令启动（推荐）

在项目目录下：

```bash
docker build --build-arg UID="$(id -u)" --build-arg GID="$(id -g)" -t cmd-ai-dev:latest .
```

把下面内容粘贴到 `~/.bashrc`，然后 `source ~/.bashrc`：

```bash
cmd_ai_dev() {
  # 关键：用交互子 bash 包一层，避免主 shell 在 Tab 补全时崩溃
  # 用 CMD_AI_DEV_INNER 防止递归
  if [ -z "${CMD_AI_DEV_INNER:-}" ]; then
    CMD_AI_DEV_INNER=1 bash -i -c 'cmd_ai_dev "$@"' bash "$@"
    return $?
  fi

  set -e

  # ====== 你需要填的配置 ======
  local OPENAI_API_KEY="填你的key"
  local OPENAI_BASE_URL="填你的base_url（可留空）"
  local OPENAI_MODEL="填你的模型名"
  local IMAGE_NAME="${CMD_AI_DEV_IMAGE:-cmd-ai-dev:latest}"
  # ===========================

  local proj_dir="${1:-$PWD}"
  if [ ! -d "$proj_dir" ]; then
    echo "目录不存在：$proj_dir" >&2
    return 1
  fi
  proj_dir="$(cd "$proj_dir" && pwd)"

  local proj_base parent_base
  proj_base="$(basename "$proj_dir")"
  parent_base="$(basename "$(dirname "$proj_dir")")"

  local cname="cmd-ai-dev-${parent_base}-${proj_base}"
  cname="$(echo "$cname" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9_.-]/-/g')"

  local base_url_args=()
  if [ -n "$OPENAI_BASE_URL" ]; then
    base_url_args=(-e "OPENAI_BASE_URL=$OPENAI_BASE_URL")
  fi

  local gitconfig_args=()
  if [ -e "$HOME/.gitconfig" ]; then
    gitconfig_args=(-v "$HOME/.gitconfig:/home/ai/.gitconfig:ro")
  fi
  local config_git_args=()
  if [ -e "$HOME/.config/git" ]; then
    config_git_args=(-v "$HOME/.config/git:/home/ai/.config/git:ro")
  fi
  local ssh_args=()
  if [ -e "$HOME/.ssh" ]; then
    ssh_args=(-v "$HOME/.ssh:/home/ai/.ssh:ro")
  fi
  local git_credentials_args=()
  if [ -e "$HOME/.git-credentials" ]; then
    git_credentials_args=(-v "$HOME/.git-credentials:/home/ai/.git-credentials:ro")
  fi
  local netrc_args=()
  if [ -e "$HOME/.netrc" ]; then
    netrc_args=(-v "$HOME/.netrc:/home/ai/.netrc:ro")
  fi
  local gnupg_args=()
  local gnupg_exec_args=()
  if [ -e "$HOME/.gnupg" ]; then
    gnupg_args=(-v "$HOME/.gnupg:/home/ai/.gnupg" -e GNUPGHOME="/home/ai/.gnupg")
    gnupg_exec_args=(-e GNUPGHOME="/home/ai/.gnupg")
  fi

  if docker container inspect "$cname" >/dev/null 2>&1; then
    # 容器存在
    if [ "$(docker inspect -f '{{.State.Running}}' "$cname" 2>/dev/null)" = "true" ]; then
      # 运行中：exec 进去跑工具（并把 key/model/base_url 注入）
      docker exec -it \
        "${gnupg_exec_args[@]}" \
        -e "OPENAI_API_KEY=$OPENAI_API_KEY" \
        "${base_url_args[@]}" \
        -e "OPENAI_MODEL=$OPENAI_MODEL" \
        -e "TERM=${TERM:-xterm-256color}" \
        "$cname" cmd-ai-dev
    else
      # 已存在但未运行：直接 start -ai（注意：env 使用创建容器时的 env；如果你改了 key/model，建议 rm 容器重建）
      docker start -ai "$cname"
    fi
  else
    # 容器不存在：创建并运行（host 网络 + 映射 /workspace）
    docker run -it --name "$cname" --network host \
      "${gitconfig_args[@]}" \
      "${config_git_args[@]}" \
      "${ssh_args[@]}" \
      "${git_credentials_args[@]}" \
      "${netrc_args[@]}" \
      "${gnupg_args[@]}" \
      -e "OPENAI_API_KEY=$OPENAI_API_KEY" \
      "${base_url_args[@]}" \
      -e "OPENAI_MODEL=$OPENAI_MODEL" \
      -e "TERM=${TERM:-xterm-256color}" \
      -v "$proj_dir:/workspace" \
      "$IMAGE_NAME"
  fi
}

alias cmd-ai-dev=cmd_ai_dev
```

之后你就可以：

```bash
cmd-ai-dev
# 或指定目录
cmd-ai-dev /path/to/your/project
```

**如果要修改OPENAI_MODEL、OPENAI_BASE_URL、OPENAI_API_KEY则需要先删除已存在的cmd-ai-dev容器，再执行cmd-ai-dev命令**

## 设计与协议

### 容器内目录约定
- `/workspace`：用户项目目录（映射到宿主机）
- `/workspace-ai`：AI 工作目录（默认不映射；用于临时脚本、日志、中间产物，避免污染仓库）
- `/workspace-ai/session.json`：会话上下文（单会话）
- `/workspace-ai/cmdout_*.log`：命令输出落盘日志
- `/workspace-ai/transcript.log`：左侧显示内容的完整记录（便于复制）

### 工具调用格式（不依赖函数调用能力）
模型需要执行命令时输出：

```
<cmd>
<time_out>60</time_out>
这里是要执行的命令（可多行）
</cmd>
这里是模型的回答（可选）
```

工具执行后回给模型：

```
<cmdout>
[exit=... timeout=0/1 interrupted=0/1]
这里是命令输出（可能截断）
</cmdout>
这里是用户的交互（可选）
```

## 特点

- 单文件实现：核心逻辑集中在一个 `cmd-ai-dev.py`，没有复杂的项目结构。
- 依赖的 AI 模型易于更改：对 OpenAI-compatible 接口友好，封装层便于替换为自发 HTTP 请求。
- 给模型高灵活性但不污染系统/项目：
  - 模型可通过命令行做几乎任何事（读写文件、跑脚本、安装包等）
  - 但运行在 Docker 容器中，宿主机更安全
  - AI 的临时产物默认落在 `/workspace-ai`，避免污染你的 Git 仓库
- 工具极简：只把“命令行”作为工具提供给模型，不引入可能受限或陌生的工具体系。
- 不依赖函数调用：自定义 `<cmd>` / `<cmdout>` 格式，即使模型不支持 function calling 也能工作。
- 左右分栏布局：模型输出在左、用户输入在右，对 16:9 屏幕更友好，适合长输出与长输入并存的场景。
- 支持 Markdown 渲染：模型的叙述输出会以 Markdown 方式渲染（`<cmd>` / `<cmdout>` 仍保持工具样式）。

## 已知缺陷

- 终端兼容性：不同终端对 TUI、IME（中文标点等）、选中复制、组合键的支持差异很大。
  - 为降低风险，提供按钮操作与备选快捷键，并将左侧内容落盘到 `/workspace-ai/transcript.log` 作为复制兜底。
  - 尝试按住shift以实现用鼠标选中文本。

## 小技巧

- 如果想查看AI工作目录的文件，你可以告诉它“请你运行/usr/bin/code-server，不要设置密码。”
- 你可以对接OpenAI API之外的任何接口/平台，将它作为支持AI编程工具的模型。
- 你可以在容器外宿主机上执行`google-chrome --remote-debugging-port=9222 --user-data-dir=./cdp-profile`，这将打开一个浏览器，然后你取消这段代码`self.llm: LLMClient = ChatZAISDKClient()`的注释并重新构建镜像，就可以将 https://chat.z.ai 网站作为支持AI编程工具的模型了。执行命令时，如果找不到google-chrome，你需要指定google-chrome二进制可执行文件的路径。

## 致谢

本项目在编写过程中参考并借助了 GPT-5.2-High 生成的代码建议与改进方案。

``````

下面是新功能：

``````md
# 操作浏览器

容器里安装谷歌浏览器、Xvfb + VNC/noVNC

通过Xvfb + VNC/noVNC实现有头浏览器+宿主机显示
宿主机显示方面，不需要VNC密码，在大模型提示词中让大模型告诉用户可以在宿主机上通过浏览器打开

在提示词中告诉大模型如何启动浏览器。我曾经使用过的命令是：
```
/var/lib/bin/google/chrome/google-chrome --remote-debugging-port=9222 --user-data-dir=./cdp-profile
```
这种命令启动的方式比用playwright启动更像真人
容器里的用户uid gid来自宿主机，一般不是root，如果是，则大模型需要加`--no-sandbox`

大模型使用python的playwright连接到浏览器并操作它

启动浏览器时可以加`--no-first-run --no-default-browser-check`以跳过向导

容器启动时需要设置`--shm-size`，防止谷歌浏览器启动不了

容器里应该有中文字体
``````

``````md
# 视觉

创建一个py文件：look_imgs.py

这个py文件顶部有：
```
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
```

这个py文件实现了一个linux命令，该命令接受多个图片文件路径，支持相对和绝对路径，无需限制路径范围。

它会使用python-magic判断是不是图片，如果有任何一个不是图片，则会报错。报错应说明哪个文件不是图片，检测到是什么。
Dockerfile中应确保python-magic已经安装

它有一个参数来限制图片的大小：`--max-size`，单位是MB，接受整数，默认是3MB，如果输入的图片中有任何一个超过这个大小，会报错。报错应说明哪个文件超过了`--max-size`，`--max-size`默认是多大。并提醒对于较大的图片应先压缩或者缩放后再调用look_imgs命令，避免因为过大导致网络传输失败或者超过OpenAI API、模型供应商的限制。

它会读取图片并转换为base64然后存到AI工作目录下的look_imgs.json中。
需要在提示词中提醒模型这里面是base64，很大很长，不要直接cat它。
同时提醒模型也不要直接cat session.json，它里面有base64，也很大很长。
若要查看它们则需要使用其他方式。

这个命令不会返回任何内容，无返回则成功，有报错会报错，注意幂等，如果报错则base64 json不应有任何内容。

cmd-ai-dev.py会在<cmd></cmd>执行之后检查是否存在look_imgs.json文件，里面有没有值，如果有，则将它们添加到messages中并清空look_imgs.json。按照现有逻辑，命令执行之后会将结果发给模型，此时图片base64会带上。
在重置会话或者停止执行的时候，也需要**按需**清空它，这部分需要多加注意。

需要将cmd-ai-dev.py中当前的OpenAI API messages格式换成支持视觉的，也就是说content字段从字符串改成数组。
这个有一定的复杂性，需要多加注意。

一旦添加到messages,就会按现有的逻辑持久化、发送给模型等
但需要编辑相关逻辑，确保在逻辑不变的情况下将messages格式换成支持视觉的。

仅对OpenAISDKClient支持视觉，其他的供应商不用支持，这个支持不应影响其他供应商，其他供应商的模型收到的内容不应因这个支持而发生改变。
``````

你可以先将需求和我对齐，确保你理解了我的意思，然后你可以给出较为具体的实现计划。但无论如何，最终的目的是实现它们，如果你理解需求并胸有成竹，现在就可以开始开发。